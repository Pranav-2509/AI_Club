{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pranav-2509/NIGHT_VISION_SELF/blob/main/Vision_Transformer_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLf2iJ1koabZ"
      },
      "source": [
        "-------------------------\n",
        "#Imports\n",
        "-------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vH-A-3-moZc_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydItLq63ToZN"
      },
      "source": [
        "--------------------------\n",
        "#Device Agnostic Code\n",
        "-------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fINZTCGhTszS"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqskNl4yUK50",
        "outputId": "e017adab-45e4-4d4c-baa4-92ff20fa4f65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "print (device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4drwJr12WH1a"
      },
      "source": [
        "------------------------\n",
        "#Loading the Data\n",
        "-----------------------"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load the MNIST dataset\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "# Define batch size\n",
        "batch_size = 64\n",
        "\n",
        "print (type(train_dataset))\n",
        "# Create DataLoaders for training and test sets\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Verify the shape of the batches\n",
        "for images, labels in train_loader:\n",
        "    print(images.shape, labels.shape)\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdAuKh9740OT",
        "outputId": "e28382de-e04e-4b54-a574-e3ed5bbf826e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torchvision.datasets.mnist.MNIST'>\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10"
      ],
      "metadata": {
        "id": "bokB87Wm4zor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQIj3aelWKPA"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import torchvision\n",
        "# import torchvision.transforms as transforms\n",
        "\n",
        "# # Define transformations\n",
        "# transform = transforms.Compose([\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5 ,0.5, 0.5))\n",
        "# ])\n",
        "# batch_size = 128\n",
        "\n",
        "# # Download and load the CIFAR-100 training set\n",
        "# trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "# # Download and load the CIFAR-100 test set\n",
        "# testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "# testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# # Classes in CIFAR-100\n",
        "# classes = trainset.classes\n",
        "# num_classes = len (classes)\n",
        "\n",
        "# # Example to iterate through the training set\n",
        "# dataiter = iter(trainloader)\n",
        "# images, labels = next(dataiter)\n",
        "\n",
        "# print('Loaded CIFAR-10 dataset')\n",
        "# print('Batch of images shape:', images.shape)\n",
        "# print('Batch of labels shape:', labels.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrd3MW4WoiIM"
      },
      "source": [
        "-------------------------\n",
        "#Splitting image into tokens\n",
        "-------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTaMij8dumwL"
      },
      "source": [
        "Patch Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVF3ulMkFnsR"
      },
      "outputs": [],
      "source": [
        "patch_size = 4\n",
        "image_dim = images[0].shape[1]\n",
        "token_length = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPkuHmSeuqPQ"
      },
      "outputs": [],
      "source": [
        "class Patch_Tokenization (nn.Module):\n",
        "  def __init__ (self, img_size, patch_size : int = 50, token_length : int = 768):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    self.img_size = img_size\n",
        "    c, h, w = self.img_size\n",
        "    self.patch_size = patch_size\n",
        "    self.token_length = token_length\n",
        "\n",
        "    self.no_tokens = (h*w)/(patch_size**2)\n",
        "\n",
        "    #Layers\n",
        "    self.split = nn.Unfold (kernel_size = self.patch_size,stride = self.patch_size, padding = 0)\n",
        "    self.linear = nn.Linear (in_features = c * (self.patch_size)**2, out_features = self.token_length)\n",
        "\n",
        "\n",
        "  def forward (self, img):\n",
        "    img = self.split (img).transpose(1, 2)\n",
        "    img = self.linear (img)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2SmugCrsdAB"
      },
      "outputs": [],
      "source": [
        "tokeniser = Patch_Tokenization (images[0].shape, patch_size = patch_size, token_length = token_length)\n",
        "tokeniser = tokeniser.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fI2Q582IFW2U"
      },
      "outputs": [],
      "source": [
        "num_tokens = int ((image_dim/patch_size )**2)       #If its not int, then it will be float"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzXHZe2jzT4k"
      },
      "source": [
        "--------------------\n",
        "#Position Encoding\n",
        "-------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VNxZ_FE0oD1"
      },
      "outputs": [],
      "source": [
        "def position_embedding (num_tokens : int, token_length : int):\n",
        "  positions = torch.zeros ((num_tokens, token_length))\n",
        "  for i in range (num_tokens):\n",
        "    for j in range (token_length):\n",
        "      angle = i/ (np.power(1000, (2* (j//2))/token_length))\n",
        "      if (j%2==0):\n",
        "        positions[i][j] = np.sin (angle)\n",
        "      else:\n",
        "        positions[i][j] = np.cos (angle)\n",
        "\n",
        "  return positions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aB0zlx_K2LVK"
      },
      "outputs": [],
      "source": [
        "position_encoding = position_embedding (num_tokens+1, token_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xcs_T_TK3QPw",
        "outputId": "0c89950a-5ab1-47b1-d691-d6284addcee3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 50, 50])\n"
          ]
        }
      ],
      "source": [
        "position_encoding = position_encoding.unsqueeze (dim = 0)\n",
        "print (position_encoding.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyFq34oQ9wn1",
        "outputId": "494bfe1b-cb61-4044-9e54-1887f75cc944"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.0000,  1.0000,  0.0000,  ...,  1.0000,  0.0000,  1.0000],\n",
            "         [ 0.8415,  0.5403,  0.6879,  ...,  1.0000,  0.0013,  1.0000],\n",
            "         [ 0.9093, -0.4161,  0.9986,  ...,  1.0000,  0.0026,  1.0000],\n",
            "         ...,\n",
            "         [ 0.1236, -0.9923, -0.8892,  ...,  0.9967,  0.0619,  0.9981],\n",
            "         [-0.7683, -0.6401, -0.9601,  ...,  0.9965,  0.0632,  0.9980],\n",
            "         [-0.9538,  0.3006, -0.5045,  ...,  0.9964,  0.0645,  0.9979]]])\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "print (position_encoding)\n",
        "position_encoding = position_encoding.to(device)\n",
        "print (position_encoding.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoOQ2dFfOsY_"
      },
      "source": [
        "------------------\n",
        "#Attention Block\n",
        "------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QMlePmbO9Gn"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self,\n",
        "                dim: int,\n",
        "                chan: int,\n",
        "                num_heads: int=1,\n",
        "                qkv_bias: bool=False,\n",
        "                qk_scale = None):\n",
        "\n",
        "        \"\"\" Attention Module\n",
        "\n",
        "            Args:\n",
        "                dim (int): input size of a single token\n",
        "                chan (int): resulting size of a single token after concatenating the heads\n",
        "                num_heads(int): number of attention heads in MSA\n",
        "                qkv_bias (bool): determines if the qkv layer learns an addative bias\n",
        "                qk_scale (NoneFloat): value to scale the queries and keys by;\n",
        "                                    if None, queries and keys are scaled by ``head_dim ** -0.5``\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        ## Define Constants\n",
        "        self.num_heads = num_heads\n",
        "        self.chan = chan\n",
        "        self.head_dim = self.chan // self.num_heads\n",
        "        self.scale = qk_scale or self.head_dim ** -0.5\n",
        "        assert self.chan % self.num_heads == 0, '\"Chan\" must be evenly divisible by \"num_heads\".'\n",
        "\n",
        "        ## Define Layers\n",
        "        self.q = nn.Linear(dim, chan , bias=qkv_bias)\n",
        "        self.k = nn.Linear (dim, chan, bias = qkv_bias)\n",
        "        self.v = nn.Linear (dim, chan, bias = qkv_bias)\n",
        "\n",
        "        #### Each token gets projected from starting length (dim) to channel length (chan) 3 times (for each Q, K, V)\n",
        "        self.proj = nn.Linear(chan, chan)\n",
        "\n",
        "\n",
        "\n",
        "    #     self._initialize_weights()\n",
        "\n",
        "    # def _initialize_weights(self):\n",
        "    #     for m in self.modules():\n",
        "    #         if isinstance(m, nn.Linear):\n",
        "    #             torch.nn.init.kaiming_uniform_(m.weight, a=0, mode='fan_in', nonlinearity='relu')\n",
        "    #             if m.bias is not None:\n",
        "    #                 nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        ## Dimensions: (batch, num_tokens, token_len)\n",
        "\n",
        "        ## Calcuate QKVs\n",
        "\n",
        "        # qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)\n",
        "        #### Dimensions: (3, batch, heads, num_tokens, chan/num_heads = head_dim)\n",
        "        q_matrix, k_matrix, v_matrix = self.q (x), self.k (x), self.v (x)\n",
        "        q_matrix = q_matrix.reshape (B, self.num_heads, N, self.head_dim)\n",
        "        k_matrix = k_matrix.reshape (B, self.num_heads, N, self.head_dim)\n",
        "        v_matrix = v_matrix.reshape (B, self.num_heads, N, self.head_dim)\n",
        "\n",
        "\n",
        "        ## Calculate Attention\n",
        "        attn = (q_matrix * self.scale) @ k_matrix.transpose(-2, -1)\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        #### Dimensions: (batch, heads, num_tokens, num_tokens)\n",
        "\n",
        "        ## Attention Layer\n",
        "        x = (attn @ v_matrix).reshape(B, N, self.chan)\n",
        "        #### Dimensions: (batch, heads, num_tokens, chan)\n",
        "\n",
        "        ## Projection Layers\n",
        "        x = self.proj(x)\n",
        "        ## Skip Connection Layer\n",
        "        v_matrix = v_matrix.reshape(B, N, self.chan)\n",
        "        x = v_matrix + x\n",
        "        #### Because the original x has different size with current x, use v to do skip connection\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample_input = torch.rand ((5, 17, 50))\n",
        "# e = Attention (50, 100, 2)\n",
        "# output = e (sample_input)\n",
        "# print (output.shape)"
      ],
      "metadata": {
        "id": "5FlvstR-V3rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkfxuD8iP3MN"
      },
      "source": [
        "----------------------------------\n",
        "#Neural Net at the end of the Encoder\n",
        "-----------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2Obl6eTP74o"
      },
      "outputs": [],
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self,\n",
        "       in_chan: int,\n",
        "       hidden_chan = None,\n",
        "       out_chan = None,\n",
        "       act_layer = nn.GELU()):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        ## Define Number of Channels\n",
        "        hidden_chan = hidden_chan\n",
        "        out_chan = out_chan\n",
        "\n",
        "        ## Define Layers\n",
        "        self.fc1 = nn.Linear(in_chan, hidden_chan)\n",
        "        self.act = act_layer()\n",
        "        self.fc2 = nn.Linear(hidden_chan, out_chan)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LELTfGA_fcEr"
      },
      "source": [
        "-----------------------------------\n",
        "#Probabilities extraction\n",
        "------------------------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iufxWehnfbt2"
      },
      "outputs": [],
      "source": [
        "class probabilities (nn.Module ):\n",
        "  def __init__ (self,in_size : int, num_classes : int):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    self.layer1 = nn.Linear (in_size, 70)\n",
        "    self.activation = nn.ReLU()\n",
        "    self.layer2 = nn.Linear (70, num_classes)\n",
        "\n",
        "  #   self._initialize_weights()\n",
        "\n",
        "  # def _initialize_weights(self):\n",
        "  #       for m in self.modules():\n",
        "  #           if isinstance(m, nn.Linear):\n",
        "  #               torch.nn.init.kaiming_uniform_(m.weight, a=0, mode='fan_in', nonlinearity='relu')\n",
        "  #               if m.bias is not None:\n",
        "  #                   nn.init.zeros_(m.bias)\n",
        "\n",
        "\n",
        "  def forward (self, x):\n",
        "    x =  (self.layer1(x))\n",
        "    x = self.activation (x)\n",
        "    x = (self.layer2(x))\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sq-pZBL54Gzt"
      },
      "source": [
        "--------------------------------\n",
        "#Encoding Block\n",
        "--------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OuF0JD3R4KGt"
      },
      "outputs": [],
      "source": [
        "class Encoding(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "       dim: int,\n",
        "       num_heads: int=1,\n",
        "       hidden_chan_mul = 4.,\n",
        "       qkv_bias = False,\n",
        "       qk_scale = None,\n",
        "       act_layer=nn.ReLU,\n",
        "       norm_layer=nn.LayerNorm):\n",
        "\n",
        "        \"\"\" Encoding Block\n",
        "\n",
        "            Args:\n",
        "                dim (int): size of a single token\n",
        "                num_heads(int): number of attention heads in MSA\n",
        "                hidden_chan_mul (float): multiplier to determine the number of hidden channels (features) in the NeuralNet component\n",
        "                qkv_bias (bool): determines if the qkv layer learns an addative bias\n",
        "                qk_scale (NoneFloat): value to scale the queries and keys by;\n",
        "                                    if None, queries and keys are scaled by ``head_dim ** -0.5``\n",
        "                act_layer(nn.modules.activation): torch neural network layer class to use as activation\n",
        "                norm_layer(nn.modules.normalization): torch neural network layer class to use as normalization\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        ## Define Layers\n",
        "        self.norm1 = norm_layer(dim)\n",
        "        self.attn = Attention(dim=dim,\n",
        "                            chan=dim,\n",
        "                            num_heads=num_heads,\n",
        "                            qkv_bias=qkv_bias,\n",
        "                            qk_scale=qk_scale)\n",
        "        self.dropout = nn.Dropout (p = 0.5)\n",
        "        self.norm2 = norm_layer(dim)\n",
        "        self.neuralnet = NeuralNet(in_chan=dim,\n",
        "                                hidden_chan=int(dim*hidden_chan_mul),\n",
        "                                out_chan=dim,\n",
        "                                act_layer=act_layer)\n",
        "\n",
        "        self.probabs = probabilities (dim, num_classes)\n",
        "\n",
        "    #     self._initialize_weights()\n",
        "\n",
        "    # def _initialize_weights(self):\n",
        "    #     for m in self.modules():\n",
        "    #         if isinstance(m, nn.Linear):\n",
        "    #             torch.nn.init.kaiming_normal_(m.weight, a=0, mode='fan_in', nonlinearity='relu')\n",
        "    #             if m.bias is not None:\n",
        "    #                 nn.init.zeros_(m.bias)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.dropout (self.attn(self.norm1(x)))\n",
        "        # print ('1', x)\n",
        "        x = x + self.dropout (self.neuralnet(self.norm2(x)))\n",
        "        # print ('2', x)\n",
        "        x = x[:, 0]\n",
        "        x = self.probabs (x)\n",
        "        # print ('3', x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYXOjZ9rB9lv"
      },
      "outputs": [],
      "source": [
        "encoder  = Encoding (dim = token_length, num_heads = 2, hidden_chan_mul = 1, qkv_bias = True)\n",
        "encoder = encoder.to (device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5_yIl9FA8jS"
      },
      "source": [
        "----------------------------\n",
        "#Training Loop\n",
        "---------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQbBCOb9d7Wz"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss ()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKgtZ6UgdkCz"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "optimizer = optim.SGD(encoder.parameters(), lr=0.005, momentum = 0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYpbJMzwA_Ur",
        "outputId": "b7643106-e78c-4111-d06e-226dac686925"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH : 1\n",
            "Train Loss for batch : 2.170410394668579\n",
            "test_loss per batch = 1.7404710054397583\n",
            "test accuracy : 0.3108\n",
            "EPOCH : 2\n",
            "Train Loss for batch : 1.5191140174865723\n",
            "test_loss per batch = 1.3463551998138428\n",
            "test accuracy : 0.5143\n",
            "EPOCH : 3\n",
            "Train Loss for batch : 1.313015103340149\n",
            "test_loss per batch = 1.1157431602478027\n",
            "test accuracy : 0.5837\n",
            "EPOCH : 4\n",
            "Train Loss for batch : 1.1352977752685547\n",
            "test_loss per batch = 0.9671016931533813\n",
            "test accuracy : 0.6466\n",
            "EPOCH : 5\n",
            "Train Loss for batch : 1.0309875011444092\n",
            "test_loss per batch = 0.903078019618988\n",
            "test accuracy : 0.6699\n",
            "EPOCH : 6\n",
            "Train Loss for batch : 0.9691396355628967\n",
            "test_loss per batch = 0.8638983368873596\n",
            "test accuracy : 0.6864\n",
            "EPOCH : 7\n",
            "Train Loss for batch : 0.9266437292098999\n",
            "test_loss per batch = 0.784250020980835\n",
            "test accuracy : 0.7234\n",
            "EPOCH : 8\n",
            "Train Loss for batch : 0.8966166973114014\n",
            "test_loss per batch = 0.8030461668968201\n",
            "test accuracy : 0.7204\n",
            "EPOCH : 9\n",
            "Train Loss for batch : 0.8419533371925354\n",
            "test_loss per batch = 0.6721391081809998\n",
            "test accuracy : 0.7693\n",
            "EPOCH : 10\n",
            "Train Loss for batch : 0.7790257334709167\n",
            "test_loss per batch = 0.6148051023483276\n",
            "test accuracy : 0.7896\n",
            "EPOCH : 11\n",
            "Train Loss for batch : 0.72484290599823\n",
            "test_loss per batch = 0.5741784572601318\n",
            "test accuracy : 0.8043\n",
            "EPOCH : 12\n",
            "Train Loss for batch : 0.6775009036064148\n",
            "test_loss per batch = 0.5765967965126038\n",
            "test accuracy : 0.8042\n",
            "EPOCH : 13\n",
            "Train Loss for batch : 0.6432679891586304\n",
            "test_loss per batch = 0.5223777890205383\n",
            "test accuracy : 0.8278\n",
            "EPOCH : 14\n",
            "Train Loss for batch : 0.6177130937576294\n",
            "test_loss per batch = 0.4949708878993988\n",
            "test accuracy : 0.8392\n",
            "EPOCH : 15\n",
            "Train Loss for batch : 0.5996641516685486\n",
            "test_loss per batch = 0.49880486726760864\n",
            "test accuracy : 0.8348\n",
            "EPOCH : 16\n",
            "Train Loss for batch : 0.5850234031677246\n",
            "test_loss per batch = 0.46349766850471497\n",
            "test accuracy : 0.8447\n",
            "EPOCH : 17\n",
            "Train Loss for batch : 0.5692267417907715\n",
            "test_loss per batch = 0.46730172634124756\n",
            "test accuracy : 0.8447\n",
            "EPOCH : 18\n",
            "Train Loss for batch : 0.5588430166244507\n",
            "test_loss per batch = 0.42937329411506653\n",
            "test accuracy : 0.8544\n",
            "EPOCH : 19\n",
            "Train Loss for batch : 0.5442144274711609\n",
            "test_loss per batch = 0.436215341091156\n",
            "test accuracy : 0.8544\n",
            "EPOCH : 20\n",
            "Train Loss for batch : 0.5361098647117615\n",
            "test_loss per batch = 0.4310104548931122\n",
            "test accuracy : 0.8586\n",
            "EPOCH : 21\n",
            "Train Loss for batch : 0.5236324667930603\n",
            "test_loss per batch = 0.405973345041275\n",
            "test accuracy : 0.8651\n",
            "EPOCH : 22\n",
            "Train Loss for batch : 0.5213605165481567\n",
            "test_loss per batch = 0.4338802695274353\n",
            "test accuracy : 0.8565\n",
            "EPOCH : 23\n",
            "Train Loss for batch : 0.5173155665397644\n",
            "test_loss per batch = 0.4144936501979828\n",
            "test accuracy : 0.8654\n",
            "EPOCH : 24\n",
            "Train Loss for batch : 0.5065046548843384\n",
            "test_loss per batch = 0.3998587429523468\n",
            "test accuracy : 0.8684\n",
            "EPOCH : 25\n",
            "Train Loss for batch : 0.5036372542381287\n",
            "test_loss per batch = 0.40157976746559143\n",
            "test accuracy : 0.8701\n"
          ]
        }
      ],
      "source": [
        "epochs = 25\n",
        "num_batches = len (train_loader)\n",
        "\n",
        "for i in range (epochs):\n",
        "  print (f'EPOCH : {i+1}')\n",
        "\n",
        "  tot = 0\n",
        "  correct = 0\n",
        "  train_loss = 0\n",
        "  test_loss = 0\n",
        "  test_acc = 0\n",
        "  for batch, (X, y) in enumerate (train_loader):\n",
        "\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "    if (batch == num_batches - 1):\n",
        "      break\n",
        "\n",
        "    encoder.train()\n",
        "    X = tokeniser (X)\n",
        "    # print (X)\n",
        "    zero_tensor = torch.zeros ((batch_size, 1, token_length))\n",
        "    zero_tensor = zero_tensor.to (device)\n",
        "\n",
        "    X_appended = torch.concat ((zero_tensor, X), dim = 1)\n",
        "    # print (X)\n",
        "    X_positional_encoded = X_appended + position_encoding\n",
        "    X_post_encoder = encoder (X_positional_encoded)\n",
        "    # break\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss = loss_fn (X_post_encoder, y)\n",
        "    train_loss+=loss\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  # break\n",
        "\n",
        "  print (f'Train Loss for batch : {train_loss/len (train_loader)}')\n",
        "  test_loss = 0\n",
        "  for batch, (X, y) in enumerate (test_loader):\n",
        "\n",
        "    tot +=len (X)\n",
        "    if (batch == len (test_loader) - 1):\n",
        "      break\n",
        "\n",
        "    encoder.eval()\n",
        "\n",
        "    X = X.to(device)\n",
        "    y = y.to (device)\n",
        "\n",
        "    X = tokeniser (X)\n",
        "    zero_tensor = torch.zeros ((batch_size, 1, token_length))\n",
        "    zero_tensor = zero_tensor.to (device)\n",
        "    X_appended = torch.concat ((zero_tensor, X), dim = 1)\n",
        "    X_positional_encoded = X_appended + position_encoding\n",
        "    X_post_encoder = encoder (X_positional_encoded)\n",
        "    test_loss += loss_fn (X_post_encoder, y)\n",
        "    X_post_encoder = torch.argmax ((X_post_encoder), dim = 1)\n",
        "\n",
        "    correct += (X_post_encoder == y).sum().item()\n",
        "  print (f'test_loss per batch = {test_loss/len (test_loader)}')\n",
        "  print (f'test accuracy : {correct/tot}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoDQ3r2foSNu"
      },
      "source": [
        "------------------\n",
        "#Experimentation\n",
        "------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kk-8TyoukY2G"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "\n",
        "# patch_size = 50\n",
        "# unfold = nn.Unfold(kernel_size=patch_size, stride=patch_size, padding=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCBOn8hjkVGg"
      },
      "outputs": [],
      "source": [
        "# x = torch.randn(1, 1, 100, 100)  # Batch size of 1, 1 channel, 100x100 image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQ5H5n3Kkhyk"
      },
      "outputs": [],
      "source": [
        "# patches = unfold(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwSGeHa8kjX5"
      },
      "outputs": [],
      "source": [
        "# print (x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tv5XJcCdkpEm"
      },
      "outputs": [],
      "source": [
        "# print (patches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Rp92KXEkvk7"
      },
      "outputs": [],
      "source": [
        "# layer = nn.Linear (in_features = 2500, out_features = 768)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Qw8WFCll0J3"
      },
      "outputs": [],
      "source": [
        "# input = torch.randn((100, 2500))\n",
        "# print (input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDzS_B4Al8-t"
      },
      "outputs": [],
      "source": [
        "# output = layer(input)\n",
        "# print (output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbGsMUe9mDQR"
      },
      "outputs": [],
      "source": [
        "# batch, sentence_length, embedding_dim = 20, 5, 10\n",
        "# embedding = torch.randn(batch, sentence_length, embedding_dim)\n",
        "# layer_norm = nn.LayerNorm(embedding_dim)\n",
        "# embedding_2 = layer_norm(embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DS7NJbJ4yIVP"
      },
      "outputs": [],
      "source": [
        "# embedding_1 = embedding[0][0]\n",
        "# mean = embedding_1.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEf5St1ZyZrq"
      },
      "outputs": [],
      "source": [
        "# var = torch.var (embedding_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eKTKE5UylAy"
      },
      "outputs": [],
      "source": [
        "# embedding_1 = (embedding_1 - mean)/(var)**1/2\n",
        "# print (embedding_1)\n",
        "# print (embedding_2[0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "og9GrLLZ9APU"
      },
      "source": [
        "experimentation for attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zonanV3f8-He"
      },
      "outputs": [],
      "source": [
        "# a = torch.rand (3, 4, 12)\n",
        "# b = a.reshape (3, 3, 2 , 4, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxxqSkGh89Ju"
      },
      "outputs": [],
      "source": [
        "# print (a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfHcjGJzywTv"
      },
      "outputs": [],
      "source": [
        "# print (b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOZa8xyAAs3U"
      },
      "source": [
        "checking how attention weights are calculated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLBQ9YZcArBQ"
      },
      "outputs": [],
      "source": [
        "batch_size, num_heads, num_tokens, head_dim = 2, 4, 5, 6\n",
        "\n",
        "q = torch.randint (1, 10, (batch_size, num_heads, num_tokens, head_dim))\n",
        "q = q.float()\n",
        "\n",
        "k = torch.randint (1, 10, (batch_size, num_heads, num_tokens, head_dim))\n",
        "k = k.float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KHnwW06BSUI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed8aef0b-2cfa-4d47-f98b-bcf22530dac2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[3., 5., 5., 2., 5., 1.],\n",
            "          [4., 8., 5., 6., 6., 9.],\n",
            "          [6., 2., 1., 7., 4., 4.],\n",
            "          [5., 7., 1., 7., 7., 2.],\n",
            "          [8., 9., 7., 5., 9., 1.]],\n",
            "\n",
            "         [[7., 2., 9., 2., 5., 6.],\n",
            "          [1., 3., 8., 7., 8., 3.],\n",
            "          [9., 3., 1., 3., 8., 8.],\n",
            "          [6., 1., 2., 6., 5., 1.],\n",
            "          [7., 2., 3., 8., 6., 2.]],\n",
            "\n",
            "         [[3., 2., 9., 7., 8., 7.],\n",
            "          [1., 1., 2., 1., 3., 2.],\n",
            "          [5., 6., 7., 6., 3., 5.],\n",
            "          [8., 9., 4., 4., 3., 2.],\n",
            "          [6., 1., 8., 6., 2., 7.]],\n",
            "\n",
            "         [[2., 3., 6., 5., 9., 1.],\n",
            "          [4., 1., 8., 6., 2., 1.],\n",
            "          [4., 9., 2., 5., 1., 7.],\n",
            "          [4., 9., 6., 3., 2., 8.],\n",
            "          [2., 8., 4., 7., 1., 2.]]],\n",
            "\n",
            "\n",
            "        [[[5., 8., 6., 8., 9., 9.],\n",
            "          [4., 9., 7., 6., 6., 2.],\n",
            "          [7., 9., 4., 9., 9., 1.],\n",
            "          [2., 5., 8., 4., 5., 1.],\n",
            "          [8., 1., 3., 6., 8., 8.]],\n",
            "\n",
            "         [[4., 7., 2., 3., 2., 8.],\n",
            "          [1., 2., 2., 8., 1., 3.],\n",
            "          [1., 9., 4., 3., 8., 1.],\n",
            "          [3., 5., 3., 2., 6., 5.],\n",
            "          [9., 9., 9., 4., 6., 2.]],\n",
            "\n",
            "         [[3., 1., 5., 4., 3., 4.],\n",
            "          [7., 3., 5., 7., 7., 6.],\n",
            "          [6., 2., 1., 5., 9., 9.],\n",
            "          [4., 5., 2., 9., 3., 1.],\n",
            "          [4., 6., 4., 8., 8., 9.]],\n",
            "\n",
            "         [[1., 7., 2., 2., 2., 4.],\n",
            "          [8., 4., 4., 6., 9., 7.],\n",
            "          [5., 9., 2., 7., 9., 5.],\n",
            "          [5., 4., 8., 6., 2., 4.],\n",
            "          [1., 1., 7., 2., 2., 3.]]]]) \n",
            " tensor([[[[8., 2., 7., 5., 1., 8.],\n",
            "          [6., 3., 6., 6., 2., 2.],\n",
            "          [7., 6., 7., 1., 3., 6.],\n",
            "          [6., 7., 2., 5., 8., 8.],\n",
            "          [3., 8., 9., 2., 5., 7.]],\n",
            "\n",
            "         [[8., 1., 5., 8., 8., 7.],\n",
            "          [8., 9., 2., 1., 5., 5.],\n",
            "          [9., 7., 3., 8., 8., 4.],\n",
            "          [8., 2., 5., 6., 7., 8.],\n",
            "          [3., 3., 7., 6., 6., 1.]],\n",
            "\n",
            "         [[7., 2., 4., 2., 3., 4.],\n",
            "          [3., 4., 2., 5., 2., 9.],\n",
            "          [9., 4., 7., 7., 2., 4.],\n",
            "          [7., 1., 1., 3., 5., 1.],\n",
            "          [3., 7., 8., 3., 2., 7.]],\n",
            "\n",
            "         [[6., 4., 7., 9., 5., 8.],\n",
            "          [5., 6., 3., 2., 4., 3.],\n",
            "          [6., 7., 8., 3., 8., 1.],\n",
            "          [9., 5., 6., 5., 4., 5.],\n",
            "          [6., 7., 1., 3., 1., 3.]]],\n",
            "\n",
            "\n",
            "        [[[4., 2., 3., 3., 5., 8.],\n",
            "          [2., 3., 5., 5., 7., 8.],\n",
            "          [6., 2., 5., 3., 2., 2.],\n",
            "          [3., 7., 3., 2., 3., 2.],\n",
            "          [9., 6., 5., 9., 8., 8.]],\n",
            "\n",
            "         [[6., 1., 7., 6., 3., 6.],\n",
            "          [6., 9., 3., 2., 8., 4.],\n",
            "          [4., 5., 9., 9., 5., 4.],\n",
            "          [3., 7., 2., 3., 1., 4.],\n",
            "          [5., 8., 2., 9., 4., 1.]],\n",
            "\n",
            "         [[6., 9., 5., 2., 8., 2.],\n",
            "          [7., 6., 4., 9., 3., 4.],\n",
            "          [8., 2., 8., 5., 2., 6.],\n",
            "          [2., 9., 8., 2., 1., 1.],\n",
            "          [9., 6., 4., 5., 7., 7.]],\n",
            "\n",
            "         [[6., 5., 6., 8., 4., 3.],\n",
            "          [7., 9., 4., 3., 5., 5.],\n",
            "          [3., 6., 6., 4., 3., 7.],\n",
            "          [5., 6., 6., 1., 8., 3.],\n",
            "          [2., 8., 8., 7., 9., 7.]]]])\n"
          ]
        }
      ],
      "source": [
        "print (q, '\\n', k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63GJAiz-BUoT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d41e0d0-263b-4a5f-e026-3e9a9b9a3d54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[8., 6., 7., 6., 3.],\n",
            "          [2., 3., 6., 7., 8.],\n",
            "          [7., 6., 7., 2., 9.],\n",
            "          [5., 6., 1., 5., 2.],\n",
            "          [1., 2., 3., 8., 5.],\n",
            "          [8., 2., 6., 8., 7.]],\n",
            "\n",
            "         [[8., 8., 9., 8., 3.],\n",
            "          [1., 9., 7., 2., 3.],\n",
            "          [5., 2., 3., 5., 7.],\n",
            "          [8., 1., 8., 6., 6.],\n",
            "          [8., 5., 8., 7., 6.],\n",
            "          [7., 5., 4., 8., 1.]],\n",
            "\n",
            "         [[7., 3., 9., 7., 3.],\n",
            "          [2., 4., 4., 1., 7.],\n",
            "          [4., 2., 7., 1., 8.],\n",
            "          [2., 5., 7., 3., 3.],\n",
            "          [3., 2., 2., 5., 2.],\n",
            "          [4., 9., 4., 1., 7.]],\n",
            "\n",
            "         [[6., 5., 6., 9., 6.],\n",
            "          [4., 6., 7., 5., 7.],\n",
            "          [7., 3., 8., 6., 1.],\n",
            "          [9., 2., 3., 5., 3.],\n",
            "          [5., 4., 8., 4., 1.],\n",
            "          [8., 3., 1., 5., 3.]]],\n",
            "\n",
            "\n",
            "        [[[4., 2., 6., 3., 9.],\n",
            "          [2., 3., 2., 7., 6.],\n",
            "          [3., 5., 5., 3., 5.],\n",
            "          [3., 5., 3., 2., 9.],\n",
            "          [5., 7., 2., 3., 8.],\n",
            "          [8., 8., 2., 2., 8.]],\n",
            "\n",
            "         [[6., 6., 4., 3., 5.],\n",
            "          [1., 9., 5., 7., 8.],\n",
            "          [7., 3., 9., 2., 2.],\n",
            "          [6., 2., 9., 3., 9.],\n",
            "          [3., 8., 5., 1., 4.],\n",
            "          [6., 4., 4., 4., 1.]],\n",
            "\n",
            "         [[6., 7., 8., 2., 9.],\n",
            "          [9., 6., 2., 9., 6.],\n",
            "          [5., 4., 8., 8., 4.],\n",
            "          [2., 9., 5., 2., 5.],\n",
            "          [8., 3., 2., 1., 7.],\n",
            "          [2., 4., 6., 1., 7.]],\n",
            "\n",
            "         [[6., 7., 3., 5., 2.],\n",
            "          [5., 9., 6., 6., 8.],\n",
            "          [6., 4., 6., 6., 8.],\n",
            "          [8., 3., 4., 1., 7.],\n",
            "          [4., 5., 3., 8., 9.],\n",
            "          [3., 5., 7., 3., 7.]]]])\n"
          ]
        }
      ],
      "source": [
        "print (k.transpose (-2, -1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFCWfHVLBgfV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c8e68ff-06de-4194-ff59-c7e0ef2d3878"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 4, 5, 6])\n",
            "torch.Size([2, 4, 5, 5])\n"
          ]
        }
      ],
      "source": [
        "print (q.shape)\n",
        "\n",
        "weights = q@ (k.transpose (-2, -1))\n",
        "\n",
        "print (weights.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5g2swEeCPDb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58c4949d-4903-412f-f0f7-924ed0950bac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 4, 5, 5])\n"
          ]
        }
      ],
      "source": [
        "weights = weights.softmax (dim = -1)\n",
        "print (weights.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBDpoLreCbhD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e91b3b90-31fd-4434-e3eb-0c2a738e4a6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[3., 5., 5., 2., 5., 1.],\n",
            "          [4., 8., 5., 6., 6., 9.],\n",
            "          [6., 2., 1., 7., 4., 4.],\n",
            "          [5., 7., 1., 7., 7., 2.],\n",
            "          [8., 9., 7., 5., 9., 1.]],\n",
            "\n",
            "         [[7., 2., 9., 2., 5., 6.],\n",
            "          [1., 3., 8., 7., 8., 3.],\n",
            "          [9., 3., 1., 3., 8., 8.],\n",
            "          [6., 1., 2., 6., 5., 1.],\n",
            "          [7., 2., 3., 8., 6., 2.]],\n",
            "\n",
            "         [[3., 2., 9., 7., 8., 7.],\n",
            "          [1., 1., 2., 1., 3., 2.],\n",
            "          [5., 6., 7., 6., 3., 5.],\n",
            "          [8., 9., 4., 4., 3., 2.],\n",
            "          [6., 1., 8., 6., 2., 7.]],\n",
            "\n",
            "         [[2., 3., 6., 5., 9., 1.],\n",
            "          [4., 1., 8., 6., 2., 1.],\n",
            "          [4., 9., 2., 5., 1., 7.],\n",
            "          [4., 9., 6., 3., 2., 8.],\n",
            "          [2., 8., 4., 7., 1., 2.]]],\n",
            "\n",
            "\n",
            "        [[[5., 8., 6., 8., 9., 9.],\n",
            "          [4., 9., 7., 6., 6., 2.],\n",
            "          [7., 9., 4., 9., 9., 1.],\n",
            "          [2., 5., 8., 4., 5., 1.],\n",
            "          [8., 1., 3., 6., 8., 8.]],\n",
            "\n",
            "         [[4., 7., 2., 3., 2., 8.],\n",
            "          [1., 2., 2., 8., 1., 3.],\n",
            "          [1., 9., 4., 3., 8., 1.],\n",
            "          [3., 5., 3., 2., 6., 5.],\n",
            "          [9., 9., 9., 4., 6., 2.]],\n",
            "\n",
            "         [[3., 1., 5., 4., 3., 4.],\n",
            "          [7., 3., 5., 7., 7., 6.],\n",
            "          [6., 2., 1., 5., 9., 9.],\n",
            "          [4., 5., 2., 9., 3., 1.],\n",
            "          [4., 6., 4., 8., 8., 9.]],\n",
            "\n",
            "         [[1., 7., 2., 2., 2., 4.],\n",
            "          [8., 4., 4., 6., 9., 7.],\n",
            "          [5., 9., 2., 7., 9., 5.],\n",
            "          [5., 4., 8., 6., 2., 4.],\n",
            "          [1., 1., 7., 2., 2., 3.]]]])\n"
          ]
        }
      ],
      "source": [
        "print (q)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwaSx1b9D2qd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "728373af-8925-4353-a485-e890782d8b7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[3., 5., 5., 2., 5., 1.],\n",
            "          [7., 2., 9., 2., 5., 6.],\n",
            "          [3., 2., 9., 7., 8., 7.],\n",
            "          [2., 3., 6., 5., 9., 1.]],\n",
            "\n",
            "         [[4., 8., 5., 6., 6., 9.],\n",
            "          [1., 3., 8., 7., 8., 3.],\n",
            "          [1., 1., 2., 1., 3., 2.],\n",
            "          [4., 1., 8., 6., 2., 1.]],\n",
            "\n",
            "         [[6., 2., 1., 7., 4., 4.],\n",
            "          [9., 3., 1., 3., 8., 8.],\n",
            "          [5., 6., 7., 6., 3., 5.],\n",
            "          [4., 9., 2., 5., 1., 7.]],\n",
            "\n",
            "         [[5., 7., 1., 7., 7., 2.],\n",
            "          [6., 1., 2., 6., 5., 1.],\n",
            "          [8., 9., 4., 4., 3., 2.],\n",
            "          [4., 9., 6., 3., 2., 8.]],\n",
            "\n",
            "         [[8., 9., 7., 5., 9., 1.],\n",
            "          [7., 2., 3., 8., 6., 2.],\n",
            "          [6., 1., 8., 6., 2., 7.],\n",
            "          [2., 8., 4., 7., 1., 2.]]],\n",
            "\n",
            "\n",
            "        [[[5., 8., 6., 8., 9., 9.],\n",
            "          [4., 7., 2., 3., 2., 8.],\n",
            "          [3., 1., 5., 4., 3., 4.],\n",
            "          [1., 7., 2., 2., 2., 4.]],\n",
            "\n",
            "         [[4., 9., 7., 6., 6., 2.],\n",
            "          [1., 2., 2., 8., 1., 3.],\n",
            "          [7., 3., 5., 7., 7., 6.],\n",
            "          [8., 4., 4., 6., 9., 7.]],\n",
            "\n",
            "         [[7., 9., 4., 9., 9., 1.],\n",
            "          [1., 9., 4., 3., 8., 1.],\n",
            "          [6., 2., 1., 5., 9., 9.],\n",
            "          [5., 9., 2., 7., 9., 5.]],\n",
            "\n",
            "         [[2., 5., 8., 4., 5., 1.],\n",
            "          [3., 5., 3., 2., 6., 5.],\n",
            "          [4., 5., 2., 9., 3., 1.],\n",
            "          [5., 4., 8., 6., 2., 4.]],\n",
            "\n",
            "         [[8., 1., 3., 6., 8., 8.],\n",
            "          [9., 9., 9., 4., 6., 2.],\n",
            "          [4., 6., 4., 8., 8., 9.],\n",
            "          [1., 1., 7., 2., 2., 3.]]]])\n"
          ]
        }
      ],
      "source": [
        "q_modified = q.transpose (1, 2)\n",
        "print (q_modified)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaaZYIk9EKAo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35b8f14d-573f-4203-9e04-54001a5beaa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[3., 5., 5., 2., 5., 1., 7., 2., 9., 2., 5., 6., 3., 2., 9., 7., 8.,\n",
            "          7., 2., 3., 6., 5., 9., 1.],\n",
            "         [4., 8., 5., 6., 6., 9., 1., 3., 8., 7., 8., 3., 1., 1., 2., 1., 3.,\n",
            "          2., 4., 1., 8., 6., 2., 1.],\n",
            "         [6., 2., 1., 7., 4., 4., 9., 3., 1., 3., 8., 8., 5., 6., 7., 6., 3.,\n",
            "          5., 4., 9., 2., 5., 1., 7.],\n",
            "         [5., 7., 1., 7., 7., 2., 6., 1., 2., 6., 5., 1., 8., 9., 4., 4., 3.,\n",
            "          2., 4., 9., 6., 3., 2., 8.],\n",
            "         [8., 9., 7., 5., 9., 1., 7., 2., 3., 8., 6., 2., 6., 1., 8., 6., 2.,\n",
            "          7., 2., 8., 4., 7., 1., 2.]],\n",
            "\n",
            "        [[5., 8., 6., 8., 9., 9., 4., 7., 2., 3., 2., 8., 3., 1., 5., 4., 3.,\n",
            "          4., 1., 7., 2., 2., 2., 4.],\n",
            "         [4., 9., 7., 6., 6., 2., 1., 2., 2., 8., 1., 3., 7., 3., 5., 7., 7.,\n",
            "          6., 8., 4., 4., 6., 9., 7.],\n",
            "         [7., 9., 4., 9., 9., 1., 1., 9., 4., 3., 8., 1., 6., 2., 1., 5., 9.,\n",
            "          9., 5., 9., 2., 7., 9., 5.],\n",
            "         [2., 5., 8., 4., 5., 1., 3., 5., 3., 2., 6., 5., 4., 5., 2., 9., 3.,\n",
            "          1., 5., 4., 8., 6., 2., 4.],\n",
            "         [8., 1., 3., 6., 8., 8., 9., 9., 9., 4., 6., 2., 4., 6., 4., 8., 8.,\n",
            "          9., 1., 1., 7., 2., 2., 3.]]])\n"
          ]
        }
      ],
      "source": [
        "q_ultra_modified = q_modified.reshape (batch_size, num_tokens, num_heads*head_dim)\n",
        "print (q_ultra_modified)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHldUQ79EaGj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}